# CPU 为加快速度采取了以下措施

## CPU 缓存

多 CPU 读取同样的数据进行缓存，进行不同运算之后，最终写入主内存以哪个 CPU 为准？在这种高速缓存回写的场景下，有一个缓存一致性协议多数 CPU 厂商对它进行了实现。MESI 协议，它规定每条缓存有个状态位，同时定义了下面四个状态：

- 修改态(Modified)一此 cache 行已被修改过（脏行），内容已不同于主存，为此 cache 专有；
- 专有态(Exclusive)一此 cache 行内容同于主存，但不出现于其它 cache 中；
- 共享态(Shared)一此 cache 行内容同于主存，但也出现于其它 cache 中；
- 无效态(lnvalid)一此 cache 行内容无效（空行）0 多处理器时，单个 CPU 对缓存中数据进行了改动，需要通知给其他 CPU。也就是意味着，CPU 处理要控制自己的读写操作，还要监听其他 CPU 发出的通知，从而保证最终

## 指令重排序

# 这些措施带来了问题

- CPU 高速缓存下有一个问题缓存中的数据与主内存的数据并不是实时同步的，各 CPU（或 CPU 核心）间缓存的数据也不是实时同步。在同一个时间点，各 CPU 所看到同一内存地址的数据的值可能是不一致的
- CPU 执行指令重扌非序优化下有一个问题：虽然遵守了 as-if-serial 语义，单仅在单 CPU 自己执行瞓青况下能保证结果正确。多核多线程中，指令逻辑无法分辨因果关联，可能出现乱序执行，导致程序运行结果错误。

# 解决方案

内存屏障处理器提供了两个内存屏障指令(MemoryBarrier)用于解决上述两个问题：

- 写内存屏障（StoreMemoryBarrier)：在指令后插入 StoreBarrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。强制写入主内存，这种显示调用，CPU 就不会因为性能考虑而去对指令重排
- 读内存屏障(LoadMemoryBarrier)·在指令前插入 LoadBarrier,可以让高速缓存中的数据失效，强制从新从主内存加载数据。强制读取主内存内容，让 CPU 缓存与主内存保持一致，避免了缓存导致的一致性问题
